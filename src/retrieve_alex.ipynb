{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving data by searching the 4TU.ResearchData API\n",
    "\n",
    "This script runs through the following steps:\n",
    "1. Define search parameters\n",
    "2. Send request to 4TU (figshare) API\n",
    "3. Converts response into pandas dataframe\n",
    "4. Stores list of article IDs\n",
    "5. Extracts file IDs from articles\n",
    "6. Downloads all files associated with all articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store token and API url\n",
    "URL='https://api.figshare.com/v2/articles/search'\n",
    "api_token = 'ac7d7197c0e1d4b51da5d374139d1db611d0f79fb0ad1584899030f1cb026dc3d6dcfe8c8ecd5f5a586c868cb85c69b13444e65c7ebafcf562aecab9f30d138d'\n",
    "\n",
    "#define search terms\n",
    "params={\n",
    "    \"search_for\":\":keyword: carbon\",\n",
    "    # \"search_for\": \"\":description: \" # w/o quotes will match any of the words included in the description field\n",
    "    \"institution\": 898, #unique 4tu code\n",
    "    \"item_type\": 3, #item type is dataset\n",
    "    \"page\": 1,\n",
    "    \"page_size\": 1000 #adjust to number larger than anticipated search results\n",
    "}\n",
    "\n",
    "# query in blocks of 10, while loop that continues until you get less than 10, so you know it's the last\n",
    "\n",
    "#full list of search terms available at https://docs.figshare.com/#articles_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#request articles based on search parameters set above\n",
    "response = requests.post(\n",
    "    url = URL,\n",
    "    json = params,\n",
    "    headers = {\"Authorization\": f\"token {api_token}\"} \n",
    ")\n",
    "\n",
    "#store response as a json object\n",
    "j = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>published_date</th>\n",
       "      <th>defined_type_name</th>\n",
       "      <th>resource_doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14747862</td>\n",
       "      <td>Bulk isotope data set supporting the manuscrip...</td>\n",
       "      <td>10.4121/14747862.v2</td>\n",
       "      <td>2021-08-26T14:38:00Z</td>\n",
       "      <td>dataset</td>\n",
       "      <td>10.1111/oik.08450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12719012</td>\n",
       "      <td>Data underlying the publication: Strontium, ox...</td>\n",
       "      <td>10.4121/uuid:f6dc4f20-a6e0-4b2f-b2f8-b79a4f9061c3</td>\n",
       "      <td>2020-03-31T00:00:00Z</td>\n",
       "      <td>dataset</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  14747862  Bulk isotope data set supporting the manuscrip...   \n",
       "1  12719012  Data underlying the publication: Strontium, ox...   \n",
       "\n",
       "                                                 doi        published_date  \\\n",
       "0                                10.4121/14747862.v2  2021-08-26T14:38:00Z   \n",
       "1  10.4121/uuid:f6dc4f20-a6e0-4b2f-b2f8-b79a4f9061c3  2020-03-31T00:00:00Z   \n",
       "\n",
       "  defined_type_name       resource_doi  \n",
       "0           dataset  10.1111/oik.08450  \n",
       "1           dataset                     "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert json object to pandas df (optional step, for analysis)\n",
    "df = pd.DataFrame.from_dict(j)[['id', 'title', 'doi', 'published_date', 'defined_type_name', 'resource_doi']]\n",
    "\n",
    "#show first few rows of df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14747862, 12719012]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract list of ids to use for download\n",
    "ids = df['id'].tolist()\n",
    "len(ids)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all the articles, retrieve the details of the article\n",
    "art = []\n",
    "for art_id in ids:\n",
    "    response = requests.get(\n",
    "        url = \"https://api.figshare.com/v2/articles/\"+str(art_id),\n",
    "        headers = {\"Authorization\": f\"token {api_token}\"})\n",
    "    art.append(pd.json_normalize(response.json()))\n",
    "\n",
    "art = pd.concat(art)[['id','files','tags','categories','custom_fields','authors','description','license.name', 'title', 'doi', 'published_date', 'defined_type_name', 'resource_doi']]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data from dictionaries nested in the art dataframe\n",
    "file_names=[]\n",
    "files=[]\n",
    "custom_fields_df = []\n",
    "author_names =[]\n",
    "categories=[]\n",
    "\n",
    "for art_id in ids:  \n",
    "    #files\n",
    "    tmp_files = pd.json_normalize(art[art['id']==art_id].iloc[0]['files'])[['id', 'name', 'is_link_only', 'download_url']]\n",
    "    tmp_files = tmp_files.assign(article_id = art_id)\n",
    "    files.append(tmp_files)\n",
    "    tmp_filename = ', '.join(tmp_files[\"name\"])\n",
    "    file_names.append(tmp_filename)\n",
    "    \n",
    "    #custom fields\n",
    "    custom_fields = ['Geolocation', 'Time coverage', 'Geolocation Longitude', 'Geolocation Latitude']\n",
    "    tmp_custom_fields_df = pd.json_normalize(art[art['id']==art_id].iloc[0]['custom_fields'])\n",
    "    tmp_custom_fields_df = tmp_custom_fields_df[tmp_custom_fields_df['name'].isin(custom_fields)]\n",
    "    tmp_custom_fields_df = tmp_custom_fields_df.set_index('name').T\n",
    "    tmp_custom_fields_df = tmp_custom_fields_df.assign(id = art_id)\n",
    "    custom_fields_df.append(tmp_custom_fields_df)\n",
    "\n",
    "    #authors \n",
    "    tmp_authors = pd.json_normalize(art[art['id']==art_id].iloc[0]['authors'])[['full_name']]\n",
    "    tmp_authorname = ', '.join(tmp_authors[\"full_name\"])\n",
    "    author_names.append(tmp_authorname)\n",
    "    \n",
    "    #categories \n",
    "    tmp_categories = pd.json_normalize(art[art['id']==art_id].iloc[0]['categories'])[['title']]\n",
    "    tmp_categoryname = ', '.join(tmp_categories[\"title\"])\n",
    "    categories.append(tmp_categoryname)\n",
    "    \n",
    "    \n",
    "    \n",
    "art = art.assign(files = file_names)   \n",
    "files = pd.concat(files)\n",
    "custom_fields_df = pd.concat(custom_fields_df)\n",
    "art = pd.merge(art, custom_fields_df, how=\"inner\", on=[\"id\"])\n",
    "art = art.assign(authors = author_names)  \n",
    "art = art.assign(categories = categories)  \n",
    "\n",
    "# Convert tags list into coma separated string\n",
    "art['keywords'] = [', '.join(map(str, l)) for l in art['tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "art.columns.values.tolist()\n",
    "art = art[['title',\n",
    "    'id',\n",
    "     'published_date',\n",
    "    'files',\n",
    "    'categories',\n",
    "    'authors',\n",
    "    'description',\n",
    "    'license.name',\n",
    "    'doi',\n",
    " 'Time coverage',\n",
    " 'Geolocation',\n",
    " 'Geolocation Longitude',\n",
    " 'Geolocation Latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>published_date</th>\n",
       "      <th>files</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors</th>\n",
       "      <th>description</th>\n",
       "      <th>license.name</th>\n",
       "      <th>doi</th>\n",
       "      <th>Time coverage</th>\n",
       "      <th>Geolocation</th>\n",
       "      <th>Geolocation Longitude</th>\n",
       "      <th>Geolocation Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulk isotope data set supporting the manuscrip...</td>\n",
       "      <td>14747862</td>\n",
       "      <td>2021-08-26T14:38:00Z</td>\n",
       "      <td>Riekenberg_Joling_Isobank_4.csv, README.txt</td>\n",
       "      <td>Ecological Applications</td>\n",
       "      <td>Philip Riekenberg, D.W. (David) Thieltges, Lon...</td>\n",
       "      <td>Bulk carbon and nitrogen stable isotope values...</td>\n",
       "      <td>CC0</td>\n",
       "      <td>10.4121/14747862.v2</td>\n",
       "      <td></td>\n",
       "      <td>Wadden Sea, North Sea</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data underlying the publication: Strontium, ox...</td>\n",
       "      <td>12719012</td>\n",
       "      <td>2020-03-31T00:00:00Z</td>\n",
       "      <td>Aruba, Bonaire, Colombia, Curacao, Dominican R...</td>\n",
       "      <td>Physiology, Geochemistry, Anthropology</td>\n",
       "      <td>Esther Plomp, S.H.M. (Suzan) Verdegaal-Warmerd...</td>\n",
       "      <td>This dataset contains the isotopic results (st...</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>10.4121/uuid:f6dc4f20-a6e0-4b2f-b2f8-b79a4f9061c3</td>\n",
       "      <td>1960/1995</td>\n",
       "      <td>Aruba, Bonaire, Colombia, Curacao, Dominican R...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        id  \\\n",
       "0  Bulk isotope data set supporting the manuscrip...  14747862   \n",
       "1  Data underlying the publication: Strontium, ox...  12719012   \n",
       "\n",
       "         published_date                                              files  \\\n",
       "0  2021-08-26T14:38:00Z        Riekenberg_Joling_Isobank_4.csv, README.txt   \n",
       "1  2020-03-31T00:00:00Z  Aruba, Bonaire, Colombia, Curacao, Dominican R...   \n",
       "\n",
       "                               categories  \\\n",
       "0                 Ecological Applications   \n",
       "1  Physiology, Geochemistry, Anthropology   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Philip Riekenberg, D.W. (David) Thieltges, Lon...   \n",
       "1  Esther Plomp, S.H.M. (Suzan) Verdegaal-Warmerd...   \n",
       "\n",
       "                                         description license.name  \\\n",
       "0  Bulk carbon and nitrogen stable isotope values...          CC0   \n",
       "1  This dataset contains the isotopic results (st...    CC BY 4.0   \n",
       "\n",
       "                                                 doi Time coverage  \\\n",
       "0                                10.4121/14747862.v2                 \n",
       "1  10.4121/uuid:f6dc4f20-a6e0-4b2f-b2f8-b79a4f9061c3     1960/1995   \n",
       "\n",
       "                                         Geolocation Geolocation Longitude  \\\n",
       "0                              Wadden Sea, North Sea                         \n",
       "1  Aruba, Bonaire, Colombia, Curacao, Dominican R...                         \n",
       "\n",
       "  Geolocation Latitude  \n",
       "0                       \n",
       "1                       "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>is_link_only</th>\n",
       "      <th>download_url</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28336731</td>\n",
       "      <td>Riekenberg_Joling_Isobank_4.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>https://ndownloader.figshare.com/files/28336731</td>\n",
       "      <td>14747862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30469620</td>\n",
       "      <td>README.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>https://ndownloader.figshare.com/files/30469620</td>\n",
       "      <td>14747862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24076859</td>\n",
       "      <td>Aruba, Bonaire, Colombia, Curacao, Dominican R...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://ndownloader.figshare.com/files/24076859</td>\n",
       "      <td>12719012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24076862</td>\n",
       "      <td>data.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>https://ndownloader.figshare.com/files/24076862</td>\n",
       "      <td>12719012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               name  is_link_only  \\\n",
       "0  28336731                    Riekenberg_Joling_Isobank_4.csv         False   \n",
       "1  30469620                                         README.txt         False   \n",
       "0  24076859  Aruba, Bonaire, Colombia, Curacao, Dominican R...         False   \n",
       "1  24076862                                           data.zip         False   \n",
       "\n",
       "                                      download_url  article_id  \n",
       "0  https://ndownloader.figshare.com/files/28336731    14747862  \n",
       "1  https://ndownloader.figshare.com/files/30469620    14747862  \n",
       "0  https://ndownloader.figshare.com/files/24076859    12719012  \n",
       "1  https://ndownloader.figshare.com/files/24076862    12719012  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = files['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_id in file_ids:\n",
    "        response = requests.get(\n",
    "            url = f\"https://api.figshare.com/v2/file/download/\" + str(file_id),\n",
    "            headers = {\"Authorization\": f\"token {api_token}\"})\n",
    "        file_name = files[files['id']== file_id].loc[:,'name']\n",
    "        open(file_name, \"wb\").write(response.content)\n",
    "\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    data.zip\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[files['id']== file_id].loc[:,'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86796"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"data.zip\", \"wb\").write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\AWILCZ~1\\AppData\\Local\\Temp/ipykernel_12252/3569770639.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'example.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not bytes"
     ]
    }
   ],
   "source": [
    "with open('example.txt', 'w') as outfile:\n",
    "    outfile.write(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\AWILCZ~1\\AppData\\Local\\Temp/ipykernel_12252/2290155947.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sample.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not bytes"
     ]
    }
   ],
   "source": [
    "response.content\n",
    "\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo:\n",
    "\n",
    "# -> adapt to reflect the keyword structure of GEF files ( anchor test etc.)\n",
    "# -> work on downloader (choose files to retrieve files, create a loop)\n",
    "# -> generalise into functions and incorporate into the main programme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5341343cf2f0463b5d542730db5c1f3b2eff882199b366cb5478e2b4f6ed60b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
